---
layout: post
title: Second Reading Speech by Minister for Law, K Shanmugam on The Protection from Online Falsehoods and Manipulation Bill
date:   2019-05-07
permalink: /news/parliamentary-speeches/Second-Reading-Speech-by-Minister-for-Law-K-Shanmugam-on-The-Protection-from-Online-Falsehoods-and-Manipulation-Bill
---


**<u>Introduction</u>**

1. This Bill comes after a long process of public consultation, beginning on the 5th of January 2018. A Green Paper by the Ministry of Law, as well as the Ministry of Communications and Information, highlighted the serious nature of the issues, and the significant impact in other countries.

2. On 5 January 2018, we asked Parliament and Parliament did so appoint a Select Committee to examine four broad issues. The Select Committee, which I will call the “SC”, held public hearings, received 169 written representations, from a broad cross-section of society. The SC then prepared a detailed, 279-page Report.

<ol start="3">
<li>Many of the issues which have been raised since the Bill was first tabled in Parliament, repeat points which were canvassed quite extensively during the SC hearings.  Points like:
  
<ul>
<li>falsehoods and how to define them, how to differentiate them from opinions</li>
<li>the possible different decision-making models – like Executive powers, Independent body, Courts</li>
</ul>
– and other such points.
</li>
</ol>

{:start="4"}
4. Some of the discussion since the Bill has been tabled, I think, has not considered what the SC has said, or the evidence that had been presented, and the balancing between different interests that the SC had to do. I hope the discussions in this House will be better informed by reference to the SC’s Report.

<ol start="5">
<li>In this speech, I will:
<ol>
<li>First, explain the existing powers in law, for dealing with objectionable material, and contrast that with the powers under the Bill</li>
<li>Second, why the Bill is being brought before this House now.</li>
<li>Third, the need and rationale for the Bill</li>
<li>Fourth, New Media and the weaponisation of falsehoods</li>
<li>Fifth, deal with some of the concerns that have been expressed,</li>
</ol>
-        and finally conclude.
</li>  
</ol>

{:start="6"}
6. My colleagues, Minister Iswaran and Senior Minister of State Edwin Tong, will deal with the key provisions of the Bill and how they implement the SC’s recommendations. Minister Ong Ye Kung will speak on the Universities. My colleagues, Minister of State Zaqy and Senior Parliamentary Secretary Sun Xueling, will also speak in addition to other Members.

<ol style="list-style-type: upper-roman; font-weight:bold">
<li><u>Comparison with Existing Law</u></li>
</ol>


<ol style="list-style-type: upper-alpha">
<li style="font-style:italic">
Existing powers are wider than the Bill’s proposed powers
</li>
</ol>


{:start="7"}
7. First, the powers that the Government has under existing legislation, they are wider than what is proposed under this Bill.

{:start="8"}
8. As we consider the Bill, the first question is: what are the Government’s powers under existing legislation? And, what can the Government do about objectionable material now? In essential respects, existing powers are wider than those proposed under the Bill.

<ol start="9">
<li>Let me return to the current legislation. We can refer to the Broadcasting Act, the Telecommunications Act and various other pieces of legislation. Collectively, they give the following powers:
<ol style="list-style-type: lower-alpha">
<li>They allow orders to be made for Take Down of any material that is objectionable, on grounds of public interest.
<br>
The statements do not have to be factual, or false. They can be true; they can be opinions. They can nevertheless be ordered to be taken down, under the current law.
</li>
<li>  Current laws also criminalize the transmission of false or fabricated messages, including on the internet.</li>
<li>Licensed newspapers, broadcasters, including on the Internet, can be required to carry clarifications and other content.</li>
<li>The Minister can make orders to restrict financing, technical support, to offending websites and restrict their reach, can block offending websites and access to objectionable material.</li>
</ol>
</li>
</ol>

{:start="10"}
10. Section 16 of the Broadcasting Act allows IMDA to direct a broadcasting licensee to “take such action” with regard to content, as it considers necessary to comply with the Act.


{:start="11"}
11. Some of these powers have existed since the 1960s. Others were added on subsequently, with the development of technology. Laws have been updated, many of these powers also apply to online material.
 

{:start="12"} 
12. The Internet revolution took off in the 1990s. In 1996, the Class Licensing Scheme under the Broadcasting Act for Internet Content Providers was put in place. The Internet Content Providers (ICPs) are automatically licensed. All have to comply with guidelines under the Class Licence Conditions and the Internet Code of Practice. IMDA has power to take down content that goes against, and I quote, “public interest, public order, national harmony,” amongst other grounds.
 

{:start="13"} 
13. In 2013, then-MDA put in place a new individual licensing scheme for news websites which report regularly on Singapore. It required online news sites to remove within 24 hours content which was in breach of standards, and post a performance bond of $50,000. The new regime harmonised the legal framework for online news sites with the framework for traditional news providers.
 
 
{:start="14"}
14. At that point in 2013, Members will recall, some persons created the “Hands Off My Internet” movement, “Free My Internet” Rally in Hong Lim. Some painted doomsday scenarios, how there is going to be a “chilling effect on free speech”, death of free speech and so on. Online statements were circulated asking netizens to “take a strong stand against the licensing regime”. There was an online petition as well.

{:start="15"}
15. All of that had little to do with the truth. Prior to the 2013 regulations, online news sites already had to comply with the same content standards. So there was no change in content standards.
 
{:start="16"}
16. Post 2013, discussions online carried on as before. So, from 1996 to 2019, 23 years that you have had the Class Licence scheme, take-downs were used mostly for sites and services with pornographic content, solicitation of sex, sex chats, religiously-offensive content, extremist content. Most people in the street don’t even know of the BA, or other legislation, and it has no impact on what they have been saying. The powers under the BA, have been used judiciously and discussions have carried on as before.

{:start="17"}
17. The arguments made in 2013, against the changes, are similar to the arguments that are being made now, and I will explain that later. They also have no connection to reality.
 
 
{:start="18"}
18. I will now make the point that the Bill provides for narrower set of powers, compared with powers that the Government already has. This is an important point, when we make philosophical arguments in this House.

<ol start="19">
<li>Earlier, I sketched out the existing powers and I have said the Bill is narrower in essential respects because it only applies to false statements of fact. In addition, it must be shown that the falsehoods are against public interest – which is set out in some detail in the Bill. The four aspects of the Bill that have been commented upon by those who are opposed:
<ol>
<li>Take down of material,</li>
<li>Take Down can be ordered by Ministers,</li>
<li>Definition of Public Interest,</li>
<li>Definition of falsehoods.</li>
</ol>
I will deal quickly with all four.
</li>
</ol>

{:start="20"}
20. First point: the BA is broader on the types of material that can be taken down. The Bill is narrower. IMDA can direct licensees to remove content. It has the power to impose further obligations on licensees through their licensing conditions, to correct falsehoods or shut down fake accounts. IMDA can also require a licensee to carry any correction as directed.
 
{:start="21"} 
21. Second point: The powers under the BA are exercised by the Minister today. There is no direct appeal to the Court. It is only by judicial review.
 
{:start="22"} 
22. Third point: Public Interest. The definition under the current law is wider, and the grounds for taking action are also broader. Any statement, whether true or false, factual or opinion, if it is objectionable against public interest, national harmony, can be ordered to be taken down, subject to judicial review. The Bill is much narrower.

<ol start="23">
<li>Fourth point: Falsehoods – how do you define? Dealing with falsehoods is not new.

<ol style="list-style-type: lower-alpha">
<li>Section 45 of Telecommunications Act (TA) criminalises falsehoods, transmitted over the Internet and other modes.</li>
<li>And the Courts have long had to deal with question of falsehoods, in the law of torts, contracts, criminal law.</li>
Section 45 of the TA was repealed yesterday, subsumed under the MOA and the Penal Code. And the relevant provision on transmitting falsehoods is now in Section 14D of the MOA, without any change. It has just been transported over.
</ol>
</li>
</ol>


<ol start="24">
<li>So some of the discussions by those opposed to this Bill, fails to consider what the SC Report has said. And seems to be without an understanding of the existing position.</li>
</ol>

<ol start="2" style="list-style-type: upper-alpha; font-weight:bold; font-style:italic">
<li>Bill gives greater judicial oversight</li>
</ol>

{:start="25"}
25. Let me now deal with the second point, it is not just narrower in scope, but it also gives greater judicial oversight, compared to the current law.
 
{:start="26"} 
26. Existing powers on take down of objectionable material, the government responses to be carried, other orders to be made, what oversight does the Court have today? It is by judicial review.

<ol start="27">
<li>According to the Bill:

<ol style="list-style-type: lower-alpha">
<li>On the determination of falsehoods, the Court oversight is by way of direct appeal. That was a considered decision by the Government. And the process will be made fast and inexpensive, for individuals.</li>
<li>Other exercise of Government powers under the Bill, judicial review will be available, as is the law now.</li>
</ol>

</li>
</ol>

{:start="28"}
28. So whatever concerns there are about the Bill, they cannot logically have been increased by this Bill. Lawyers will know, when you have a narrower Bill, and the facts come within the narrower Bill, as opposed to the broader law in general, the narrower Act will apply. So in fact it represents a narrowing of the current position.

<ol start="29">
<li>So as Members speak, I hope the debate will be based on an understanding of the current position. And I will do that by putting a series of questions.

<ol>
<li>Does the current law already criminalize transmission of falsehoods? The answer is yes. Does the Bill take a narrower position? Answer is yes. So these arguments about definition of fact: These concerns cannot be new. We had similar provisions all this while with less judicial oversight. How does the bill increase the concerns?</li>
<li>Second, Take Downs, Corrections, are they possible now? Answer is yes.</li>
<li>Third, can a Minister order take downs now? Answer is yes.</li>
<li>Fourth, can a Minister order take downs on broader grounds than under the Bill? The answer is yes.</li>
<li>Fifth, does the Bill give greater judicial oversight? Answer is yes.  </li>
</ol>

</li>
</ol>

<ol start="3" style="list-style-type: upper-alpha; font-weight:bold; font-style:italic">
<li>Why not rely on existing legislation?</li>
</ol>

{:start="30"}
30. So having said that, Members can then ask: If the power is narrower in these essential respects, why introduce this legislation? Why not just rely on existing legislation?


<ol start="31">
<li>The existing legislation, with broad powers, have been in place for some time. After the SC process, we decided to have new legislation:
<ol style="list-style-type: lower-alpha">
<li>with a narrower set of powers than under existing legislation,</li>
<li>focused on online falsehoods with remedies that are calibrated, and</li> 
<li>provide for greater judicial oversight over Executive action,</li>
</ol>
    
</li>  
</ol>

{:start="32"}
32. The Bill is designed specifically for the Internet rather than relying on existing legislation, and to deal specifically with online falsehoods rather than the broader areas that are covered under the BA.

<ol start="33">
<li>An alternate approach was entirely possible, which would be to rely on existing legislation, with slight tweaks and add subsidiary legislation. If we relied on existing legislation, what we want to achieve under this Bill can be achieved as follows.

<ol style="list-style-type: lower-alpha">
<li>First, we can rely on the BA as it is now, for Correction Directions, Takedown Directions, General Correction Directions, and demonetisation to some extent.</li> 
<li>Section 16 of the BA allows IMDA to direct a licensee to “take such action” with regard to content as it considers necessary to comply with the Act. So that will be the BA, and then you have subsidiary legislation under the BA, which can be passed with Account Restriction Directions, Declaration of Online location, advertising levers.</li>
<li>Then we move on to the existing Class Licence scheme which can also be amended through subsidiary legislation, to cover provision of content by individual publishers, and clarify that internet intermediaries like Facebook and Google are also covered.
<br>
So all of this, could have been done, under subsidiary legislation.
  
</li>
<li>The only thing that would have required a statutory amendment, would have been one point under the Broadcasting Act: to the territoriality provision, to include internet intermediaries based outside of Singapore. But that really is not in dispute. I don’t think anyone in this House will say we should not cover internet intermediaries based outside Singapore.</li>
</ol>  
  
</li>  
</ol>

{:start="34"}
34. If we had taken this alternate approach, the powers would have been broad and there would be less judicial oversight. Issues that have been raised - Fact versus Falsehoods, Public Interest, Ministerial action, all, -  there would be no amendments needed for the legislation. We can rely on existing legislation. 
 
{:start="35"} 
35. Members can therefore see, if we had relied on existing legislation with the appropriate amendments - and if you map that against the issues that have been raised in public: Fact versus Falsehoods, Public Interest, Ministerial action to take down, there would have been no need to amend.
 
{:start="36"} 
36. If we had taken that approach, the result would have been a blunt instrument, with none of the calibration that the Bill proposes or the extent of judicial oversight, which is also going to be made speedier under the current proposals.
 
{:start="37"} 
37. The BA was essential at its time, to achieve the objective of that Act. It provides a balanced framework applicable to all forms of broadcast content.
 
{:start="38"} 
38. The Bill on the other hand was fashioned to deal specifically with falsehoods that can be spread online with incredible speed, in a targeted manner, and to address such falsehoods, with speed, with proportionality, and with the Courts given greater powers.
 
{:start="39"}
39. That is why the Bill is preferable. That explains the background.

<ol start="2" style="list-style-type: upper-roman; font-weight:bold;">
<li><u>Need and Rationale for the Bill</u></li>  
</ol>


{:start="40"}
40. What is the need and rationale for the Bill, what are the substantive reasons for the Bill?

<ol start="41">
<li>To understand that, we need to look at this larger context. Trends around the world affecting –
<ol style="list-style-type: lower-alpha">
<li>the very foundations of democracy,</li>  
<li>seriously impacting societies,</li>
<li>affecting free flow of ideas, honest discussions, and</li>
<li>strangling the marketplace of ideas.</li>
</ol>  
</li>  
</ol>

{:start="42"}
42. This Bill is an attempt to deal with some of these very real, serious risks which all societies face. But at the same time, in a carefully considered manner, with the government deciding that we should come before the House, and put forward something that in a way cuts down on the existing powers. And put forward a new Bill that actually restricts government’s powers compared with today, but focused on online falsehoods. And voluntarily, compared with existing legislation, say, if the House agrees, let us give greater oversight to the judges, and let us make it much faster. So that is the true nature of the exercise.
 
{:start="43"} 
43. But the Bill is not a silver bullet. It cannot address all the issues.
 
{:start="44"} 
44. I will ask Members to bear with me as I set this out because it is important for both Members, and the public, to understand the larger picture before we can understand why this Bill is necessary.
 
{:start="45"} 
45. The SC dealt with a part of the issue, but if you take one step back, what is the fundamental problem in many countries today? It is really a serious loss of trust in Governments, in institutions which are both public and private, including the political system, the media, the professions, businesses, financial institutions and so on.


<ol start="46">
<li>What is the reason for the loss of trust? Several factors, I will mention four.
<ol style="list-style-type: lower-alpha">
 
<li>First, inequality and inequity</li> 
<li>Second, political systems not delivering.<br>
These developments have been aided by at least two other factors –
</li>
<li>The way traditional media has been behaving, and</li>
<li>Effect of New Media.</li>
</ol>  
  
</li>  
</ol>  

{:start="47"}
47. This loss of trust, in turn has led to destructive populism, in many countries, with serious consequences for democracies.
 
{:start="48"} 
48. I will ask Members to bear with me as I explain each because what we are facing, is a very serious situation, across the world, and we will face it. This is not something to be taken lightly. I think the very seriousness of what we are facing, what many other countries in the world are facing, has to be understood. Not just this legislation, but everything that we are going to do, as a Parliament, as a Government, as a society hereafter, has got to be seen in the context of what is happening.

<ol style="list-style-type: upper-alpha; font-weight:bold; font-style:italic">
<li>Trust</li>  
</ol>

{:start="49"}
49. First, trust.

{:start="50"}
50. Trust in institutions is important for society’s well-being and prosperity.

<ol start="51">
<li>These are institutions that deliver public goods for society:

<ol style="list-style-type: lower-alpha">
<li>The Executive,</li>  
<li>Parliament,</li>
<li>The Courts,</li>
<li>Army,</li>
<li>Police,</li>
<li>and other institutions like:
<ul>
<li>media,</li>
<li>healthcare system,</li>
<li>banks,</li>
<li>professions,</li>
<li>universities.</li>
</ul> 
  
</li>
</ol>  
  
</li>  
</ol>  

{:start="52"}
52.  Institutions are the building blocks of democratic societies. People depend on institutions to deliver economic and societal benefits.
 
{:start="53"} 
53.  Institutions play a crucial stabilising role. They serve to manage diversity, hold communities together, keep extremist politics at bay.


<ol start="54">
<li>Institutions, in turn, depend on trust and legitimacy to work, to –
<ol style="list-style-type: lower-alpha">
<li>persuade the public to make sacrifices for the common good</li>  
<li>encourage societies to cooperate and come together, to solve problems,  </li>
<li>implement policies successfully,</li>
<li>take action for society’s benefit, and</li>
<li>steer countries through crises</li>
</ol> 
</li>  
</ol>  

{:start="55"}
55. When people lose trust in institutions, that creates a vicious cycle. Studies show for example, low trust in the medical system has an impact on public health - management of disease outbreaks. Take law enforcement – perceived legitimacy of police is crucial to effective law enforcement. We can give examples in all sectors.
 
{:start="56"} 
56. But the basic point is, when trust in institutions is lost, society suffers, everyone suffers.


<ol start="57">
<li>What is the situation in the West, in many countries? In Western democracies, trust in governments is falling, significantly.
<ol style="list-style-type:lower-alpha">
<li>Europe: the percentage of Europeans who trust their national governments has fallen from 36% to 29% over the last ten years. There is a decline in nearly all countries in Europe.  </li>
<li>US: In the United States, a 2018 Pew Research Center study shows public trust at “near historic lows”. In 2019, only 17% trust the Government. The percentage of Americans with “a great deal of confidence” in the Courts? 16%. 45% do not have much confidence. In the Presidency, 19% have great deal of confidence. 54% have not much confidence.  Americans have the least confidence in Congress, their Parliament, 8% have a great deal of confidence, 71% not much confidence.</li>
</ol> 
  
</li>  
</ol> 


{:start="58"}
58. Trust in other important public institutions is also falling. In the media, medical profession, legal profession, many others. And it is all borne out by data. 

<ol start="59">
<li>Singapore in comparison so far is OK.  We were first included in the Edelman Trust Barometer in 2011.
<ul>
<li>Trust in Government has been good. We have been in the top “Trust” category and the Government is one of the most trusted institutions in Singapore. Trust in Government in 2019 was at 67 points, compared to average of 26 countries at 47.</li>  
<li>Trust in mainstream media, we are 7th out of 26 countries.</li>
</ul>  
</li>  
</ol>  

{:start="60"}
60.  But we cannot ignore the global risks.  And we are likely to be impacted by the same forces.
 
{:start="61"} 
61.  Loss of trust in America has been described by the Wall Street Journal as “not merely a problem, but a crisis.” It speaks to a loss of trust in the political system as a whole, and in democracy itself. What has led to this loss of trust? I highlighted four factors amongst several, let me touch on them briefly.

<ol start="2" style="list-style-type: upper-alpha; font-weight:bold; font-style: italic">
<li>Rising inequality, inequity</li>  
</ol>  


<ol start="62">
  <li>First: rising inequality, inequity in many parts of the world.
  
  <ol style="list-style-type: lower-alpha">
  <li>If you take the US, the top 0.1% of US households hold the same amount of wealth as the bottom 90%. In US, the average salary of a CEO is 354 times the average salary of a worker.</li>
  <li>In the UK, on the eve of Brexit, UK reached its wealthiest position in its modern history. Yet in the previous two years, the overall wealth of the poorest 20% of UK households declined by 9%.</li>
  <li>It is a global problem. 70% of people live in a country that has seen a rise in inequality in the last 30 years. By 2030 it is estimated that the richest 1% could own two-thirds of the global wealth.</li>
  </ol>
  
  </li>
</ol>  

{:start="63"}
63. So that is one part, inequality, it is a very serious issue. And it is an issue in Singapore as well.

<ol start="3" style="list-style-type: upper-alpha; font-weight:bold; ">
  <li>Political systems not delivering</li>  
</ol>  

{:start="64"}
64. Second, political systems not delivering.
 
{:start="65"} 
65. In absolute terms, living standards in most countries have risen compared with previous generations. But absolute numbers are just one part of the picture – you have to look at the reality of people’s lives.
 
{:start="66"} 
66. People’s lives are not improving. Three indicators amongst many – social mobility, quality of public education, jobs.
 
{:start="67"} 
67. Social mobility in the world’s richest countries has stalled since the 1990s. As of 2018, in the UK it took five generations, about 150 years for a child from the bottom 10% in terms of income to reach the average national income. In France, in Germany, it took six generations, 180 years.
 
{:start="68"} 
68. In the US, the public education system, the serious deficiencies have been documented. And low investments in public education is one reason for lower social mobility.

<ol start="69">
<li>So people lose faith in democracy as a whole. People give up, they give up on governments, they don’t think governments can deliver. US, Australia, UK, the Netherlands, New Zealand, Sweden, and other countries: the percentage of people who say that it is “essential” to live in a democracy has fallen significantly, especially amongst the young.
<ol style="list-style-type: lower-alpha">
<li>Less than one-third of Americans below the age of 35, say it is absolutely important to live in a democracy.</li>
<li>From 1995 to 2017, the share of French, Germans, and Italians who favoured military rule went up more than 3 times.</li>
<li>From 1995 to 2014, the share of Americans who favoured military rule rose 2.5 times, from 1 in 16 to 1 in 6. Imagine that, 1 in 6. In America. </li>
</ol>
  
</li>  
</ol>

{:start="70"}
70. So the desire for an upending of the status quo has serious consequences, de-stabilisation, global effects. Democracy itself is under serious threat. It will be very unwise for us to watch and do nothing because it can sweep us over very quickly.
 
{:start="71"} 
71. I believe we are at one of those crucial turning points in history. it may not quite be Gotterdammerung, but a turn for worse.
 
{:start="72"} 
72. This weakening of democracy and institutions has been powered by a series of contributing factors. I will mention two. Media and New Media.


<ol start="4" style="list-style-type: upper-alpha; font-weight:bold; font-style:italic">
<li>Media</li>
</ol>

{:start="73"}
73. First, the media. Media has, in other countries, played a highly corrosive role, in eroding trust in many ways.
 
{:start="74"} 
74. In Australia, media played a major role in the ousting former Australian Prime Ministers Kevin Rudd and Malcolm Turnbull. Media attacked Malcolm Turnbull savagely and regularly, because a media owner didn’t agree with Turnbull’s government policies, in particular on climate change. And Media became an active participant in politics and decided outcomes.
 
{:start="75"} 
7785. As he was being ousted, Turnbull said and I quote: “The reality is that a minority in the party room, supported by others outside the Parliament, have sought to bully, intimidate others into making this change of leadership that they’re seeking”.
 
{:start="76"} 
76. Kevin Rudd, another former Prime Minister, was also ousted by the media. He wrote a scathing article and said, Rupert Murdoch ran a campaign to destroy his government in the 2013 elections. Murdoch’s papers began attacking Rudd because Rudd planned to build a National Broadband Network that would be good for Australia, but Murdoch’s cable monopoly would face greater competition. So Rudd was ousted.
 
{:start="77"} 
77. Rudd described Murdoch as “the greatest cancer of the Australian democracy”, and I quote, “A political bully and a thug who for many years has hired bullies as his editors. The message to Australian politicians is clear: either toe the line on what Murdoch wants or he kills you politically.” He described, and I quote, “a cowering, fearful political culture across the country”. Fear of personal repercussions, if you challenged Murdoch’s interests, and said that Murdoch’s print media had “a disproportionate impact on setting the day’s overall agenda”, using a “masterful conflation of ‘opinion’ with ‘news’”. Such media environment erodes trust in Government.
 
{:start="78"} 
78. If you look at Britain, the baleful influence of Media in British politics is well documented. Look at a Guardian report in 2011. It said Blair “paid court” to Murdoch, securing Murdoch’s patronage, Murdoch gave Blair the power to shut out detractors, used his newspapers to help Blair beat down his rival, Brown. Brown, on the other hand, used the Daily Mail as a platform.
 
{:start="79"} 
79. Murdoch was opposed to the EU. When asked why, Murdoch reportedly said: “When I go into Downing Street they do what I say; When I go to Brussels they take no notice.” Murdoch has since denied saying it. But the City Editor of The Times, Hilton, has stood by his account of what Murdoch said to him.
 
{:start="80"} 
80. Kevin Rudd made the point that “Murdoch made Brexit possible because of the position taken by his papers.” Not just Murdoch’s newspapers, others as well.


<ol start="81">
<li>Steven Barnett, a prominent parliamentary advisor, and a Professor of Communications in the UK, said: <br /> &ldquo;In the lead up to the June 23 European Union referendum, British mainstream media failed spectacularly. Led, inevitably, by the viscerally anti-EU Daily Mail, Sun, Daily Express, Telegraph, most of Britain&rsquo;s national press indulged in little more than a catalogue of distortions, half-truths and outright lies. It was a ferocious propaganda campaign in which facts, sober analysis, sacrificed to the ideologically driven objectives, of editors and their proprietors.&rdquo;</li>
</ol>

{:start="82"}
82. The Pro-Leave Camp in UK - The Daily Mail, The Daily Express, The Sun, The Daily Telegraph – combined readership of 28 million monthly readers, used sensational headlines, outright lies.
 
Sunday Express: “12 million Turks would move to the UK” if Turkey joined the EU. It later admitted it was inaccurate.  
 
{:start="83"} 
83. Government on the one side, people on the other - Media is the intermediary. If the Media regularly trade in lies to attack the Government without basis, this happens. Trust in Government goes down. Institutions will be severely damaged. The Media can destroy institutions.
 
{:start="84"} 
84. An example of a great institution that has been savaged is the UK Courts, among the best in the world. I have spoken about this in the House previously. I do not wish to go into it but I have in the attachment set out how the British Media have severely damaged the British Judiciary.
 
{:start="85"} 
85. Traditional media holds power over society’s information. It has the ability to influence minds and viewpoints. When media acts responsibly, it serves democracy. When they do not, it damages democracy.

{:start="86"}
86. In many countries, traditional Media has played a big role, in the loss of trust.
 
{:start="87"} 
87. I spoke about inequality, inequity, political systems not delivering, media abusing its power, New Media being abused. I have sketched out the first three. New Media is the subject of this Bill. I will come back to it and deal with it in greater detail.
 
{:start="88"} 
88. Let me first complete the larger point on the consequences of the four aspects coming together. Members can then see what happens when you don’t deal with the very real danger of these developments.


<ol start="5" style="list-style-type: upper-alpha; font-weight:bold; font-style: italic">
<li>Consequences: Populism</li>  
</ol>  

{:start="89"}
89. In an active democracy, foundations include trust, free speech and the infrastructure of fact. The four elements I referred to have combined like a battering ram to damage, destroy these foundations.
 
{:start="90"} 
90. When people lose trust, when they lose faith, when there is no proper public discourse, when infrastructure of fact is damaged, then democracy, societies are at serious risk. Populism will rise. Violence will rise, particularly towards the minorities, the weak. The ability of countries to face challenges, will be weakened.
 
{:start="91"} 
91. The crisis of trust in many countries has opened wide the doors to dangerous, destructive politics: Populism.
 
<ol start="92">
<li>Populism both exploits and deepens the loss of faith in the system, making it harder for institutions to correct and to find solutions.
<ol style="list-style-type: lower-alpha">
<li>Gallup has said, and I quote, when people hold “low trust in government and low or static expectations for their future lives”, support for populist, anti-establishment politics increases.
<br>
This is a politics that can – and has, in some countries, destroyed democracy and replaced it with corruption.
    
</li>

<li>The 2017 Edelman Trust Barometer drew a direct link between the lack of trust in public institutions, and these populist movements. 44% of those who voted to leave the EU believed the system was failing, and held fears about at least 1 major societal issue, compared with 20% of those who wanted to remain in the EU.</li>

</ol>
  
</li>  
</ol>  

{:start="93"}
93. Populists used these fears as ammunition, to feed the crisis of trust in institutions. And 2016 saw populist movements make major gains.           
 
{:start="94"} 
94. The Eurasia Group said, populism is a force in US politics. In Europe, populist political parties are getting close to or are in government positions in several countries. Populism also reigns in some Latin American countries, and has gained footholds in Asia. In the assessment by Eurasia Group, populism is “likely to intensify and spread over the coming decade, weakening governments and de-legitimizing political leaders as a consequence.”
 
{:start="95"} 
95. The result will be a set of unyielding, centrifugal forces, creating a global environment described by the Eurasia Group as “the most dangerous it’s been in decades”.
 
{:start="96"} 
96. This is the serious situation that faces many countries and we will face it as well. That is why I referred to Gotterdammerung earlier.
 
{:start="97"} 
97. Many issues – inequality, inequity, political systems failing to deliver, traditional Media, New Media, the impact leading to loss of Trust and to Populism. We have to avoid this trajectory. This means, we have to deal with each of the issues.
 
{:start="98"} 
98. This Bill is an attempt to deal with one part of the problem: the serious problems arising from falsehoods spread through New Media. To try and help support the Infrastructure of Fact and promote honest speech in public discourse. It is an important part – even as we work on other aspects.
 
{:start="99"} 
99. Now I turn to falsehoods and New Media.


<ol start="6" style="list-style-type: upper-alpha; font-weight:bold; font-style:italic">
<li>Falsehoods and New Media</li>  
</ol>  

(1) *<u>Fundementals</u>*


{:start="100"}
100. Many societies, including ours, are pluralistic and diverse, with competing interests and identities.  With religious diversity as well. Various interest groups, NGOs, other associations. Each pursues its interests, causes and passions.
 
{:start="101"} 
101. Such diversity is never easy to navigate. It can give rise to instability and conflict. James Madison, one of the American founding fathers, argues that the “factions” in a diverse society cannot be controlled, only the effects of such factions can be countered. Decision-making with diversity is not always easy.
 
{:start="102"} 
102. A key foundation of a democracy is public discourse. Ideally, public discourse will help citizens understand complex policy issues, it will guide policy-makers to make optimal decisions, it will shape differing viewpoints, and expand common ground.
 
{:start="103"} 
103. But public discourse can only take place when there is free and responsible speech.
 
{:start="104"} 
104. The pre-requisites for national conversations are a common vocabulary, an underpinning of facts, and that provides a platform for accommodation and compromise amongst diverse voices in society. 
 
{:start="105"} 
105. A critical piece of infrastructure in these conversations is fact, and the infrastructure of fact. Like public infrastructure, society depends on it. It provides society with a shared reality. This is necessary so that we can have diversity without conflict, and public participation, while still getting decisions made. Without it, our political system will malfunction.
 
{:start="106"} 
106. William Davies, the English Sociologist and political economist has said, and I quote:  “The fact that millions of people are able to believe the same things about reality is a remarkable achievement, but one that is more fragile than is often recognised.”
 
{:start="107"} 
107. A critical reason for this remarkable achievement, and I quote Davies again, is “something so ubiquitous, so ordinary, that we scarcely ever stop to notice it: trust.”
 
{:start="108"} 
108. This is the trust that when public institutions – the Government, Media, other Institutions – share a piece of information with the public, they do so honestly. Trust in public institutions is a cornerstone of the infrastructure of fact.
 
{:start="109"} 
109. The belief in the authenticity of the source, whether it be the media, the Government, experts, or other authoritative sources, makes society accept facts.
 
{:start="110"} 
110. Authenticity of course has to be earned and maintained. And if a usually trusted source is not telling the truth, there must be avenues to expose, and there must be consequences. So that rigour helps in maintaining authenticity. People will then believe, if it is said, it is likely to be true. And if not true, it will be exposed.
 
{:start="111"} 
111. These are amongst the foundations on which modern societies are based. They are bigger than the Government of the day, they are bigger than any political party.  This is about the basic structure of society.

(2) *<u>Exploitation of New Media</u>*

{:start="112"}
112. New Media has been heavily exploited, to batter this Infrastructure of Fact. Which in turn, weakens trust, in public discourse, in institutions, in democracy itself. 
 
{:start="113"} 
113. I will now set out how falsehoods have been weaponised, to attack the infrastructure of fact, to destroy trust, and to attack societies.
 
{:start="114"} 
114. New Media is an information super highway, it has got many byways, links to different groups in society, and to everyone. It has now been used to send out on an industrial scale, falsehoods to mislead people. Broad sections targeted, but specific groups and individuals are targeted.

<ol start="115">
<li>The attack using falsehoods on social media, comes from several directions, several sources.
<ol>
  <li>One, foreign countries using information warfare</li>  
  <li>Two, profit-driven actors</li>
  <li>Three, deliberate actors, for political ends, and</li>
  <li>Four, people with prejudices, seeking to harm other groups.</li>
</ol> 
 The SC noted this. 
</li>  
</ol>  


(3) *<u>Sources of Falsehoods</u>*

{:start="116"}
116. Let us look at some sources of Falsehoods.

<ol style="list-style-type: lower-roman">
  <li>Foreign State actors</li>  
</ol>  


{:start="117"}
117. First, foreign countries.
 
{:start="118"} 
118. There is a military doctrine that has been developed for the Internet age. General Gerasimov, Russia’s military Chief of Staff, there is a doctrine named after him called the Gerasimov Doctrine. Basically, he says, the “rules of war” have changed. Non-military measures, including information operations, they can be harnessed to, in turn harness the “protest potential of the population”.
 
{:start="119"} 
119. What does it mean? Information operations can target and create internal opposition as a “permanently operating front” throughout the target country. These non-kinetic military measures, in many cases, can exceed the power, as his doctrine says, the power of force and weapons. Even though military or overt violent measures are not being used, the target states’ national sovereignty, security are threatened and violated.
 
{:start="120"} 
120. In this way, the lines between war and peace have now blurred. And wars no longer have to be declared.
 
{:start="121"} 
121. Security experts gave evidence to the SC.  Dr Shashi Jayakumar said that in modern information warfare, I quote, “seeding internal opposition within the target country is extremely important.” And he said that he “technological tsunami” has given aggressor states the ability to “subvert individual slices” of the target country in a manner unthinkable just two to three decades ago.
 
{:start="122"} 
122. A national security expert from Latvia, Dr Berzins said the notion of a broken social contract is the main vulnerability exploited by foreign adversaries. In his words, “[i]t is easier for the adversary to achieve its objectives if the society of the state being attacked believes that their country is a failed state that does not care for the interests and needs of the population, and the loss of current statehood will bring better living conditions.”
 
{:start="123"} 
123. Singapore is a specific, and vulnerable target, for some very precise reasons. It has military superiority in this region – experts said this. That superiority in conventional forces means it will be futile to start a war with Singapore. Therefore, militarily weaker countries will then focus on other means to weaken Singapore, sap our will from inside, create deep internal divisions and keep us in a permanent state of internal dissension.
 
{:start="124"} 
124. The evidence is that this is already happening. The SC heard it, we know that it is happening, even though we don’t come out in public and say it very openly. It is happening to sap people’s support for the SAF, for defense, to try and shift Singapore’s foreign policy as well. And these are not issues that we should dismiss lightly. Just assuming we go on the basis of the evidence that we have heard at the SC, it has happened elsewhere, and I will give you some evidence that this has happened.
 
{:start="125"} 
125. Take Ukraine, a foreign country, which the SC didn’t really name, used falsehoods to build a narrative that the Ukrainian government was fascist and corrupt. It spread online falsehoods about atrocities being carried out against a particular community in Ukraine. For example, that Ukrainian soldiers had crucified a child, which was later debunked. Volunteers who fought against Ukraine said they were motivated because of these supposed atrocities. Consequences: loss of sovereignty, part of territory, loss of lives.
 
{:start="126"} 
126. If you take the Czech Republic, disinformation operation by a foreign country, was used to turn domestic sentiments in favour of a foreign State’s geopolitical goals. One objective was to make people believe the US was responsible for influx of Syrian refugees into Europe, and the conflict in Ukraine. The disinformation appears to have had some effect. 2016: 50.2% of Czechs believed the US is responsible for Syrian refugees coming to Europe, 38% believed that the Ukrainian crisis was caused by the US and NATO. So, it was done to weaken Czech support for NATO and Ukraine.
 
{:start="127"} 
127. Take Germany. If it can happen in the UK and it can happen in Germany, I think it can easily happen here. A girl fabricated a claim that she had been assaulted by three Middle Eastern migrants. Foreign media outlets reported on that widely, suggesting it was true, specifically from one country. Reports were then spread on social media. Berlin authorities investigated, confirmed the girl’s claim had been fabricated. But falsehoods were circulated online, that the police had failed to follow up on the case. Thousands demonstrated on the streets, to “expose” the government’s attempts to cover up the crimes perpetrated by the refugees. That same year, a far-right populist party made unprecedented gains in the regional elections, and most of its support came from the same minority constituency as the girl who made the rape claim.
 
{:start="128"} 
128. Sweden. The Swedish defence agency says false information about subjects such as NATO, immigration, terrorism, are spread “on a daily basis in Sweden”. 
 
{:start="129"} 
129. Many of these countries, trust is being eroded in institutions, populism is on the rise.
 
{:start="130"} 
130. Since Russia’s name had come up in the media, the SC invited Russia to help us and the Russian Embassy very helpfully sent us a letter, that Russia is also very concerned about fake news and has been victim of fake news. So we have no doubt that Russia takes this matter very seriously.

<ol start="2" style="list-style-type: lower-roman">
  <li>Profit-seekers</li>  
</ol>  

{:start="131"}
131. Next, apart from foreign state actors, commercial profit, another dimension.
 
{:start="132"} 
132. Digital advertising models have turned websites into virtual real estate. So value depends on the attention attracted, with every click, every view, digital ad revenue is earned.
 
{:start="133"} 
133. This business model has created an attention economy. Content that stokes fear and anger and good for attracting attention. Falsehoods can help people earn large sums of money, and have political impact.

<ol start="134">
  <li>In the US, an American named Paul Horner, he set up at least 20 fake news websites, some used deceptive URLs and it tricked readers into thinking that they were mainstream sources, like ABC News, CNN. He was prolific, he used his websites to publish fake stories, stoke partisan engagement, claimed that they were satirical; said he assumed people would fact-check. But many did not, and they were fooled. Some examples of his falsehoods:
  <ol style="list-style-type: lower-alpha">
    <li>During a government shutdown, President Obama used his own money to keep open a government funded Muslim culture museum. Fox News reported the story as a fact, before retracting it.</li>
    <li>False article – protestors were paid to protest against Mr. Trump. Re-tweeted by the Trump campaign.</li>
    <li>20 million Amish people had committed to vote for Mr. Trump. Turned up in Google News, had 750,000 page views in two days.</li>
  </ol>
  </li>  
</ol>  


{:start="135"}
135.    He made $10,000 a month from Google AdSense. He was opposed to President Trump, but targeted conservatives with his fake stories, because he found it more profitable.
 
{:start="136"} 
136. A BuzzFeed news investigation found a network of at least 43 websites which together published more than 750 fake news articles – a small study. All of them used Google AdSense to earn digital advertising revenue.
 
{:start="137"} 
137. Towards the end of the 2016 US Presidential Elections, a small town in Macedonia became well known, the registered home of at least 100 pro-Trump websites, filled with sensational falsehoods, Macedonians experimented with different target audiences, fake stories could gain the most traction amongst Trump supporters, they found. Sometimes they wrote their own articles, but often would just re-use falsehoods from alt-right websites in the US. In the four months leading up to the Elections, one young Macedonian earned nearly US$16,000 from two websites he ran. For five or six hours of work, he could earn about $1,000 a month
 
{:start="138"} 
138. So as Samanth Subramanian, a reporter with WIRED, said and I quote, “This is the… disturbing heart of the affair: that the internet made it so simple for these young men to finance their material whims and that their actions helped deliver such momentous consequences”.

<ol style="list-style-type: lower-roman" start="3">
  <li>Deliberate actors, for political ends</li>  
</ol>  


{:start="139"}
139. Third category, deliberate individual actors.
 
{:start="140"} 
140. You have foreign state actors, you have people doing it for money, now people and groups who do it deliberately. The SC found that in several countries both local and foreign civilians had spread falsehoods for political causes, affecting both their own countries, and other countries as well.


<ol start="141">
  <li>For example: far-right, nationalist groups, promoting more extreme politics.
<ol style="list-style-type: lower-alpha">
  <li>The domestic alt-right in the US used falsehoods, drove major false narratives, during the 2016 US Presidential Elections.</li>
  <li>More recently in 2018, Brazilian Presidential Elections, local far-right groups coordinated network of fake social media accounts, spread misinformation in support of right-wing candidates.</li>
 </ol> 
  </li>  
</ol>  

{:start="142"}
142. Populists use lies to attack institutions, invoke divisive rhetoric. They use conspiracy theories to explain complex issues in simple terms, and trying to make people believe them. Truth then becomes completely irrelevant. Even the most extreme lies which we might think people will normally dismiss, become believed and it impacts very badly on public life.
 
{:start="143"} 
143. So British historian and journalist Anne Applebaum said this about populist movements, and I quote: “They don’t require belief in a full-blown ideology … most of them don’t deploy propaganda that conflicts with everyday reality. And yet…all of them encourage their followers to engage, at least part of the time, with an alternative reality.”


*Brexit Referendum*

{:start="144"}
144. In the UK, falsehoods were spread extensively during the EU Referendum. Immigration was a key issue. I spoke earlier about false claims in traditional media about Turks, Turkey, and Brexit. Digital advertisements were also run by the Leave EU Campaign. That Turkey was joining the EU, 12 million Turks would in that event move to the UK, if it remained in the EU.
 
{:start="145"} 
145. Foreign interference was also at play. Fake foreign-linked accounts posted more than 45,000 messages about Brexit, in the 48 hours during the referendum. A large part of foreign-linked content related to refugees, immigration, false stories, stories of illegal migrants attacking women – concocted.
 
{:start="146"} 
146. But these falsehoods  were used to create an alternative reality. If you believed them, you would believe there was a conspiracy by the ruling elite to turn the UK and Europe into a Muslim caliphate. Muslims were campaigning for Sharia law to govern the UK, the Mayor of London, a Muslim, was sponsoring them. And in the UK, there are areas where Sharia law dominates and non-Muslims cannot enter.
 
{:start="147"} 
147. Sounds outlandish. Who would believe? The British are very sensible people. But even the British fell for it. In 2018, YouGov did a survey of over 10,000 people. It was a substantial survey. 32% believed the falsehood about ‘no go’ areas under Sharia law in the UK.  49% of those who voted to leave the EU stated that this was true.
 

{:start="148"}
148. It also created a permissive environment for hate. In the month after the referendum, there was a 41% spike in hate crimes and the majority of crimes were motivated by race, including crimes against migrants.
 
{:start="149"} 
149. Brexit altered the course of British history, it is one of the most important events in their recent history, and the massive falsehood campaign, may have well affected the outcome.
 
{:start="150"} 
150. An investigative report in The Guardian, by a British journalist Caroline Cadwalladr, explained this. She went to a town in Wales that probably received more EU funds than any other town, and still voted to leave the EU, 62% of them voted to leave. In this town, the EU was funding a 350-million-pound regeneration project, a 33-million-pound college for further education, which had 29,000 apprenticeships for young people to learn a trade, a 77-million-pound road improvement scheme, and a 30-million-pound railway line. The town had one of the lowest rates of immigration in the country, it was in Wales, which was a net EU beneficiary.
 
{:start="151"} 
151. But when Caroline interviewed the people in town, she discovered the existence of an alternative reality. People believed the town was sending more money to the EU than it was receiving, the EU had not only done nothing for the town, it had also brought a huge immigration problem, including from Turkey.
 
{:start="152"} 
152. The Welsh town had been a left-wing Labour stronghold. Yet the people were repeating information usually found in right-wing newspapers. She discovered that they were getting their information or misinformation from targeted digital ads on Facebook.
 
{:start="153"} 
153. One of the most controversial claims in the UK during the referendum was that the UK sends 350 million pounds a week to the EU. Not only plastered on buses, but also run as digital ads aimed at specific groups of voters. The UK Statistics Authority said that the figure was likely closer to 136 million pounds per week. Despite the corrections, a 2018 King’s College London study found that 42% of people who had heard this claim still believe it to be true, and 22% were unsure, only 30% correctly believed that it was false.
 
{:start="154"} 
154. For a referendum that may have irreversibly altered the course of British history, these are serious consequences.


*US experience*


{:start="155"}
155. In the US as well, falsehoods and lies have been spread on a massive scale.  A study from Stanford University shows that on average, each American adult read about three false stories in the months leading up to the 2016 US Election. The researchers compiled the fake stories that had been debunked by fact-checking websites. Found that these falsehoods were shared about 38 million times, leading to around 760 million engagements with the content.
 
{:start="156"} 
156. The false narratives were driven by the people who identified with the home-grown alternate-right movement. Largely sought to denigrate the establishment, attack Mrs Clinton’s campaign.
 
{:start="157"} 
157. Also at play: a sophisticated foreign information campaign, that sought to influence the outcome, undermine democratic institutions, and the democratic ideals.
 
{:start="158"} 
158. There was the conspiracy theory that Mrs Clinton and other top Democrats were part of a child paedophilia ring operating out of a Pizza restaurant, in Washington, DC. Sounds completely crazy, utterly unbelievable if you think about it. The rumours began on Twitter, spread to other websites and online forums. Claims got louder. Hacked emails from Mrs Clinton’s campaign were distorted to support the conspiracy theory.
 
{:start="159"} 
159. An American man showed up at the pizza restaurant to “self-investigate,” and he brought a gun along with him.  People demonstrated in front of the White House, declaring that the theory was real.
 
{:start="160"} 
160. The falsehoods helped created an alternate reality. One where a “deep state” existed within US institutions which was conspiring against the American people. And if you were part of this echo chamber, you would be told that then-President Obama was colluding with the UK spy agency to spy on Mr. Trump. Mrs Clinton was linked to a mysterious explosion that killed one of her employees. And the 2018 Florida school shooting was really a secret government operation.
 
{:start="161"} 
161. Foreign agents infiltrated, exploited this alt-right movement using fake social media accounts. They pretended to be real Americans. Amplified the falsehoods that originated from these websites. Targeted echo chambers with claims that Mrs Clinton wanted to apply Sharia law in the US, that Mrs Clinton was actively arming the terrorist group ISIS.
 
{:start="162"} 
162. Foreign agents also infiltrated other social media movements, to spread falsehoods on both sides of issues – they were agnostic about that - and to create more division. They amplified the falsehoods, they widened the divide. The political ground became fragile, fraught, and conducive for foreign agents to operate.
 
{:start="163"} 
163. The experiences of these two countries show how, through a combination of falsehoods and digital technology, the foundations of democratic society are severely attacked.  Falsehoods are used to undermine public trust which is the cornerstone of our infrastructure of fact. They are used to divide and polarise, tearing the social fabric. And democratic discourse, accommodation and compromise become very difficult. In these conditions, the political centre becomes hollowed out, and people are driven to extremes.

*France’s Yellow Vest movement*

{:start="164"}
164. If you take France, the Yellow Vest movement. At the centre of the movement are these “Anger Groups” on Facebook. They are online hubs for falsehoods. They appeared almost a year before the street protests began in Paris. In the lead up to the protests, falsehoods were used to increase the sense the system was failing, and turning against the people.
 
{:start="165"} 
165. Various falsehoods that the French Constitution had been nullified in 2016 by the then-Prime Minister; that President Macron was going to sign France’s sovereignty away at a UN conference; a million Germans had protested increased fuel prices; that President Macron wrote to Paris police to use force against protestors and so on.
 
{:start="166"} 
166. During the protests, Misinformation in Yellow Vest Facebook groups and pages reached over 105 million views over 4 million shares, in 5 months. Images were falsely captioned as of bleeding Yellow Vest protestors. These were used to claim that media and government were hiding police brutality and violence against these protestors.
 
{:start="167"} 
167. During the 2016 US Presidential Election disinformation came from foreign operatives. But in the mid-term elections, such campaigns were more domestic. Americans were targeting other Americans, using the same strategies that are said to have been introduced by the Russians.  
 
{:start="168"} 
168. Sometimes, activists worked with foreign States.  The SC Report has pointed out that State actors have formally coordinated with, co-opted, other private sector actors including Private industry, Civil society organisations, Fringe movements, and volunteers who ideologically support the cause. The SC Report also mentioned that an Asian country, didn’t name it, is said to have an online cyber army, and volunteers who promote the government’s policies and attack those who criticize those policies.

<ol start="4" style="list-style-type: lower-roman">
  <li>People seeking to spread hate</li>  
</ol>  

{:start="169"}
169. Social media has also enabled hate to thrive. Falsehoods are often centerpieces of hate propaganda.

<ol start="170">
<li>Over the past few years, people have used online falsehoods to promote anti-immigrant, anti-Muslim prejudices.
<ol style="list-style-type: lower-alpha">
<li>After terrorist attack in Paris in 2015, a video was posted, described as showing “Moderate Muslims” celebrating the attack. It was actually a video of people celebrating a cricket match victory in Pakistan. But nearly 500,000 views within a few hours. Video was spread again after the terrorist attack in Paris in 2017, with same false caption.</li>
<li>The terror attack at Westminster in London in 2017 - a photograph of a Muslim woman walking past victims became viral. She was speaking on her phone, face hidden from view. Falsely accused of ignoring the victims, and treating the attack casually. It was later discovered that the tweet originated from a fake foreign account.</li>
<li>When moderate Muslims demonstrated against terrorism in London. A false story was spread that the demonstration was staged.</li>
<li>In April this year, falsehoods were used to turn the Notre Dame fire into an anti-Muslim narrative. A fabricated quote ascribed to a Muslim US senator saying, “they reap what they sow”. A video of Notre Dame burning with shouts of “Allahu Akbar” edited over.</li>
 <li>In Indonesia, a “Muslim Cyber Army” used falsehoods and hate speech to inflame sentiments against gays, Chinese.</li>
</ol>
  
</li>  
</ol>  


{:start="171"}
171. We have also seen this in Germany, Italy and Brazil. And all have rising populism. This is no coincidence.



<ol style="list-style-type: lower-roman" start="5">
  <li> Scale</li>  
</ol>  

{:start="172"}
172. Psychological evidence is that mere exposure to conspiracy theories, even if they are dismissed, makes people less likely to accept official information, or engage in politics. Conspiracy theories harm trust in institutions overall, not just the specific institutions that they relate to.
 
{:start="173"} 
173. And so, people mistrust the very existence of an Infrastructure of fact and disengage from public discourse altogether. As William Davies said, “…when trust sinks beneath a certain point, many people may come to view the entire spectacle of politics and public life as a sham…”


<ol start="174">
<li>In the digital age, almost anyone can make a falsehood go viral, or run a disinformation campaign.
<ol style="list-style-type: lower-alpha">
<li>It has happened in Sri Lanka.</li>
<li>In India, child abduction rumours spread on WhatsApp - 69 mob attacks, 33 deaths.</li>
<li>In Mexico, Child abduction rumours sparked a horrific lynching of two men.</li>
<li>This year, in France, child abduction rumours targeting the Roma people led to several violent attacks on the Roma.</li>
<li>Harm to public health when falsehoods are spread about health care.</li>
<li>Financial markets can be affected very quickly. A false tweet that the White House had been bombed led to a massive fall in the stock market.</li>
</ol> 
</li>  
</ol> 


{:start="175"}
175. The examples are innumerable. Every country, this is happening.
 
{:start="176"} 
176. No one can disagree that this is a serious threat. And that it has to be dealt with head on.
 
{:start="177"} 
177. I will say this to Members of this House on both sides, and the NMPs. If and when this happens in Singapore, there will be deep damage to the institutions, which are beyond and above politics. We are seeing this happen before our very eyes in other countries which normally you could have assumed were stable, much more stable than Singapore, much bigger than Singapore. And if that happens, that will damage society beyond repair. So there is no benefit to anyone regardless of any political persuasion. There is no benefit to see this happen because there is no benefit whether political or otherwise in seeing this happen.  For anyone.



(4) *<u>Tools used to spread falsehoods</u>*

{:start="178"}
178. What are the tools such actors use, and what is the cost of such tools? The digital technology has given falsehoods a new power. The SC found, “…considerable evidence was given showing how modern digital technology has made the creation and dissemination of falsehoods easier, cheaper, more profitable, transforming it.


<ol start="179">
<li>I will mention three tools:
<ol>
<li>Fake accounts</li>  
<li>Digital advertising</li>
<li>Algorithms used by platforms to rank content</li>
</ol>

<ol style="list-style-type: lower-roman">
  <li>Fake Accounts</li>  
</ol>  

  
  
  </li>  
</ol> 

{:start="180"}
180. Fake accounts have been described as “foot soldiers” of disinformation. They may be run either by humans, known as “trolls”; or may be automated, in which case they are called “bots”.
 
{:start="181"} 
181. Fake social media accounts are manufactured to manipulate. Some of them cultivate persuasive online personas, gain followers, both real and fake. Used as fictitious leaders of public opinion, using falsehoods to sway minds, create impressions of public sentiment.
 
{:start="182"} 
182. Bots are used to artificially amplify falsehoods, megaphone for falsehoods.They draw attention to falsehoods, affirm them, and make them appear to be more believable.
 
{:start="183"} 
183. Digital advertising tools are used to target falsehoods at susceptible segments of the population.
 
{:start="184"} 
184. Search engine results manipulated so that false articles are prioritised.
 
{:start="185"} 
185. Online echo chambers are created and exploited. Social media groups and online chats are used to polarise and mobilise people to orchestrate conflict.


<ol start="186">
<li>Falsehoods today travel easily and widely across multiple platforms. In 2017, a news article that a Russian aircraft had managed to electronically disable a US warship, was posted on a Russian state-controlled news site.
<ol style="list-style-type: lower-roman">
<li>The article used a parody that had been published a few years before, and presented it as truth. You can see how it is not just the labels that matter. People can be made to believe that parody is in fact true. There is a need to look at the material objectively. It was designed to glorify Russia and undermine confidence in the US Navy.</li>
<li>In 2 days, it was picked up by mainstream outlets in the US and Europe. You can see how it spreads. In less than 7 days, cross-posted on dozens of news sites, and their social media pages, catered to different countries and demographics. Fox News’ version was shared over 27,000 times. The Sun’s version was shared over 10,000 times.</li>
</ol>
</li>  
</ol>  


<ol start="187">
<li>Some of the more prominent examples over the last 3 years:
<ol style="list-style-type: lower-alpha">
<li>In 2016 Brexit, research suggests that bots were generating up to 20% of Brexit-related tweets in the months leading to the Referendum, including anti-Muslim falsehoods.</li>
<li>In the 2016 US Presidential Election, a foreign troll factory conducted a disinformation campaign using 50,000 bot accounts, over 3,800 fake Twitter accounts, and at least 470 fake Facebook accounts. Facebook’s best estimate from 2015 to 2017, approximately 126 million people may have received content from accounts associated with this troll factory.  </li>
<li>In the 2017 French Presidential Elections, emails from then-candidate Macron’s campaign were hacked and leaked. So #Macronleaks hashtag was used to guide Twitter users to false claims that the leaked emails showed evidence of illegal activity by Macron.  Hashtag was amplified through network of trolls and bots. Reached 47,000 tweets in less than 4 hours after the initial tweet.</li>
<li>“Coordinated inauthentic behaviour” by fake accounts was also seen in 2018 US Mid-Term Election, 2018 Brazilian Presidential Election, the US anti-vaccine debate, and in Indonesia.</li>
</ol>
</li>  
</ol>  


<ol start="188">
<li>Fake accounts have been used in very sophisticated ways.
<ol style="list-style-type: lower-alpha">
<li>A Twitter account belonging to one “Jenna Abrams” was created in 2014. This appeared to belong to a young American woman. Once she built a following, she pushed a divisive set of views on immigration and Trump, especially closer to the 2016 Election. At one point, she had over 70,000 followers, was quoted by dozens of high-profile media outlets, including The Washington Post, the BBC and the New York Times. But it turned out to be a fake account created by a foreign troll agency.</li>
<li>The Twitter account impersonating the Tennessee Republican Party, also created by the same foreign troll agency, spread falsehoods such as President Obama had admitted he was Muslim, an employee of Clinton’s was killed in a mysterious explosion in Washington, DC and Clinton was involved. At one point, it had over 152,000 followers. The real Tennessee Republican Party account had less than 14,000 followers.</li>
</ol>
</li>  
</ol>  

{:start="189"}
189. Trolls, bots, can, and have been, used in Singapore. We have noticed spikes in activity from inauthentic accounts when we have discussions on various issues of public concern. One example, whenever there is a bilateral issue with Malaysia, these goes up. We recently estimated it went up by 30%. 
 
{:start="190"} 
190. Such activity creates alternate realities; it manipulates perception, creates impression that there are many voices, shouts down other viewpoints through fake accounts, shifts public opinion, erodes trust and undermines institutions.

<ol start="2" style="list-style-type: lower-roman">
  <li>Digital advertising</li>  
</ol>  

{:start="191"}
191. If you turn to digital advertising. It is done to sway public opinion, used on both sides of the Atlantic. Foreign operatives were using it in a disinformation operation to influence the US Elections. It was also being used by the Vote Leave campaign in the UK.
 
{:start="192"} 
192. These tools allow messages to be micro-targeted with a high degree of precision at specific groups, based on a variety of indicators, including people’s fears and prejudices. They are able to do so because personal data on each user is harvested by platforms like Facebook.
 
{:start="193"}
193. In the US, foreign operatives used US$100,000 to spread Facebook advertisements to 126 million Americans. It’s inexpensive, compared with traditional advertising. Almost 2,000 ads used interest-based targeting, and of those, 800 were geographically targeted, including at swing states. And remember, in some swing states, the margin of victory was in the tens of thousands.

{:start="194"}
194. In the UK, the Vote Leave campaign in Brexit spent more than £2.7 million on targeted advertisements.
 
{:start="195"} 
195. Targeted digital advertising was used in these campaigns because it was effective. Study by network theorists showed when falsehoods are initially aimed at those predisposed to believe them, they spread further.
 
{:start="196"} 
196. Another troubling aspect of targeted advertising is that it is hidden from public view. Others cannot see the falsehoods being spread and they are unable to step in to correct them.

{:start="197"}
197. Again, as British journalist Carole Cadwallader said in a Ted Talk, “*…this entire referendum took place in darkness, because it took place on Facebook. And what happens on Facebook stays on Facebook, because only you see your news feed, and then it vanishes, so it's impossible to research anything. So we have no idea who saw what ads, what impact they had, what data was used to target these people. Or even who placed the ads, how much money was spent, even what nationality they were.*”

<ol start="3" style="list-style-type: lower-roman">
  <li>Algorithms</li>  
</ol>  

{:start="198"}
198. Third, the algorithms. They can play a big role in promoting falsehoods. Roger McNamee, who was an early investor and advisor to Facebook, said this about 2016 US Elections, “*Facebook’s algorithms have played a huge role in this election cycle by limiting each member’s news feed to ‘things they like,’ which effectively prevents people from seeing posts that contradict their preconceptions. Trolls on both sides have exploited this bug to spread untruths and inflame emotions.*”
 
{:start="199"} 
199. Platforms’ algorithms have boosted conspiracy theories, false claims, to the top of search results, recommendation lists, and news feed rankings. By giving them prominence, the falsehoods are made to seem more credible. Ranking does matter. One study has found that manipulating search engine results to favour one candidate over another can alter voter preferences by 20%.

<ol style="list-style-type: lower-roman" start="4">
  <li>Disinformation industry</li>  
</ol>  


{:start="200"}
200. The spread of falsehoods is also aided by service providers in a growing commercial disinformation industry.

